# rag-mistral7B

This notebook is an implementation of retrieval augmented generation (RAG) with Mistral 7B. It allows to use Mistral to query on a document and extract information from it using natural language. It uses Llama-index as library to create the vector store to query the document. The model used to create the document embedding is bge-small-en-v1.5. The notebook was implemented in a Colab environment. 
